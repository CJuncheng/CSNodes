# Computer Network Notes
<h2 align="left">目录</h2>
[toc]

## 计算机网络概述


### 计算机网络结构
网络结构主要包括：网络边缘、网络核心、接入网和物理媒介三部分组成.
#### 网络边缘
网络边缘：

- 端系统/Host/主机：
   - CS(Client/Service): 运行应用程序；如 Web、email
   - P2P: 文件分发方式，多线程；如迅雷、电驴
- 采用网络设施的面向连接服务 (TCP)
- 用基础设施的无连接服务 (UDP)

#### 网络核心
网络核心：分组交换机和和路由器等构成的网状网格.
**电路交换**
端到端的资源被分配给从源端到目标端的呼叫“call”：独享资源，个呼叫一旦建立起来就能够保证性能；如果呼叫没有数据发送，被分配的资源就会被浪费 (no sharing)；要求建立呼叫连接；通常被传统电话网络采用.

电路交换网络中的复用：**频分 (FDM), 时分 (TDM), 波分 (WDM)**.

电路交换不适合计算机之间的通信:
- 连接建立时间长
- 计算机之间的通信有突发性，如果使用线路交换，则浪费的片较多
   - 即使这个呼叫没有数据传递，其所占据的片也不能够被别的呼叫使用
- 可靠性不高

**分组交换**
以分组为单位存储-转发方式, 资源共享，按需使用
- 网络带宽资源不再分分为一个个片，传输时使用全部带宽
- 主机之间传输的数据被分为一个个分组.
- 资源共享，不用建立呼叫

1. 存储转发传输：分组每次移动一跳（hop ）
   - 在转发之前，节点必须收到整个分组
   - 延迟比电路交换要大
   - 排队时间
   - 端到端时延：$d_{端到端} = N\frac{L}{R}$
   - 按照有无网络层的连接，分成
     - 数据报网络
     - 虚电路网络
2. 排队时延与分组丢失（网络拥塞）
   - 如果到达速率 > 链路的输出速率:
     - 分组将会排队，等待传输
     - 如果路由器的缓存用完了，分组将会被抛弃 (出现分组丢包)

**电路交换和分组交换比较**
同样的网络资源，分组交换允许更多用户使用网络；此外，分组交换适合于对突发式数据传输

**网络的网络**
端系统通过接入**ISPs** (Internet Service Providers) 连接到互联网，包括：住宅，公司和大学的 ISPs。接入 ISPs 相应的必须是互联的，因此任何 2 个端系统可相互发送分组到对方，致的“网络的网络”非常复杂，其发展和演化是通过经济的和国家的政策来驱动的。

![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/isp.jpg)

#### 接入网和物理媒介
**接入网**
1. 家庭接入
   - modem: 调制解调（调频、调幅、调相位、综合调制）；电话和互联网不能同时占用
   - DSL(利用电话公司现有的本地电话基础设施)：
   ![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/dsl.jpg)
      - 采用现存的到交换局 DSLAM 的电话线
         -  DSL 线路上的数据被传到互联网
         - DSL 线路上的语音被传到电话网
      - < 2.5 Mbps 上行传输速率 (typically < 1 Mbps)
      - < 24 Mbps 下行传输速率 (typically < 10 Mbps)
   - 电缆网络 (利用有线电视现有的有线电视基础设施)：
     - FDM: 在不同频段传输不同信道的数据，数字电视和上网数据（上下行）
2. 企业接入网络：主要以太网和 WIFI: 端系统经常直接接到以太网络交换机上，带宽较大，然后通过wifi 下发给用户。
3. 无线接入网络: 各无线端系统共享无线接入网络（端系统到无线路由器）
   - 无线 LANs: 建筑物内部的无线 wifi 网络
   - 广域无线接入: 由电信运营商提供 (cellular)，包括 4G, 5G 

**物理媒介**
Bit: 在发送-接受对间传播
物理链路: 连接每个发送-接收对之间的物理媒体
1. 导引型媒体
   - 双绞线：5 类，6 类
   - 同轴电缆：一粗一细
   - 光纤和光缆
2. 非导引型媒体
   - 开放的空间传输电磁波或者光信号，在电磁或者光信号中承载数字数据
   - 双向
   - 受传播环境影响: 反射、吸收、干扰
   - 类型：地面微波、WiFi、蜂窝数据（如 4G）、卫星

### 计算机网络的性能指标
**分组组交换中的时延**
1. 处理时延
   - 检查分组首部和决定将分组导向何处;
   - 检查比特级别的差错.
2. 排队时延和丢包
   - 在输出链路上等待传输的时间
   - 依赖于路由器的拥塞程度
3. 传输时延
   - L= 分组长度 (bits)
   - R= 链路带宽 (bps)(传输速率)
   - 传输时延 = L/R
   - 存储转发延时
4. 传播时延
   - d= 物理链路的长度
   - s= 在媒介的传播速度 ( 2 × 108m/sec)
   - 传播时延 = d/s
   - 存储转发延时

节点延时:
\[
   d_{nodal} = d_{pro} + d_{queue} + d_{trans} + d_{prop}
\]
其中，
- $d_{pro}=$ 处理延时
   - 通常是微秒数量级或更少
- $d_{queue}=$ 排队延时
   - 取决于拥塞程度
- $d_{trans}=$ 传输延时
   - = L/R, 对低速率的链路而言很大（如拨号），通常为微秒级到毫秒级
- $d_{prop}=$ 传播延时
   - 几微秒到几百毫秒

端到端的时延:
\[
   d_{end-end} = N(d_{pro} + d_{queue} + d_{trans} + d_{prop})
\]

**吞吐量**
1. 吞吐量: 在源端和目标端之间传输的速率（数据量/单位时间）
   - 瞬间吞吐量: 在一个时间点的速率
   - 平均吞吐量: 在一个长时间内平均值
2. 瓶颈链路: 端到端路径上，限制端到端吞吐的链路
   - 端到端平均吞吐 = min{R1, R2, · · · , Rn}

### 网络协议层次及其服务模型

**Internet 协议栈**

- 应用层: 网络应用
   - 研究网络应用程序的核心就是写出能够运行在不同端系统和通过网络彼此通信的应用进程程序。
   - FTP, SMTP, HTTP,DNS
- 传输层: 主机之间的数据传输(在2个进程之间，很可能只体现在端系统上(TCP连接))
   - 在网络层提供的端到端通信基础上，细分为进程到进程，将不可靠的通信变成可靠地通信
   - TCP, UDP
- 网络层: 为数据报从源到目的选择路由(在2个主机之间，涉及到路径上的一些路由器)
   - 主机之间的通信，端到端通信，不可靠
   - IP, 路由协议
- 链路层: 相邻网络节点间的数据传输 
   - 2 个相邻 2 点的通信，点到点通信，可靠或不可靠
   - 点对对协议 PPP, 802.11(wifi), Ethernet
- 物理层: 在线路上传送 bit

**ISO/OSI 参考模型**
在互联网协议栈的应用层和传输层之间添加表示层和会话层

- 表示层: 允许应用解释传输的数据, e.g., 加密，压缩，机器相关的表示转换
- 会话层: 数据交换的同步，检查点，恢复

> 互联网协议栈没有这两层!

**封装和解封装**

![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/network_level.jpg)

![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/ip_layer.png)

TCP MSS与MTU:TCP MSS（Maximum Segment Size）是指TCP协议所允许的从对方收到的最大报文长度，即TCP数据包每次能够传输的最大数据分段，只包含TCP Payload，不包含TCP Header和TCP Option。MSS是TCP用来限制application层最大的发送字节数。为了达到最佳的传输效能，TCP协议在建立连接的时候通常要协商双方的MSS值，这个值TCP协议在实现的时候往往根据MTU值来计算（需要减去IP包头20字节和TCP包头20字节），所以通常MSS为1460=1500(MTU)- 20(IP Header) -20 (TCP Header)。
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/MTU_MSS1.png)

**各层次的协议数据单元**

- 应用层：**报文**(message)
- 传输层：**报文段**(segment)：TCP 段，UDP 数据报
- 网络层：分组 packet（如果无连接方式：**数据报**datagram）
- 数据链路层：**帧**(frame)
- 物理层：**位**(bit)









## 应用层
研究网络应用程序的核心就是写出能够运行在不同端系统和通过网络彼此通信的**应用进程程序**。网络核心没有应用层软件。网络应用程序是由成对的进程组成，在**客户-服务器应用程序体系结构**下，研究客户端进程（发起通信的进程）和服务器进程通信（等待连接的进程）。不同主机，通过交换报文（Message）来通信：
- 使用OS提供的通信服务
- 按照应用协议交换报文(借助传输层提供的服务)

**套接字(Socket)** 是同一台主机内应用层与运输层之间的接口，也被称为应用程序和网络之间的 **应用程序编程接口**。
> 应用程序开发者可以控制套接字在应用层端的一切，但对该套接字的运输层端几乎没有控制权（仅限于：运输层协议选择，或者设定几个运输层参数）。**无论UDP还是TCP都没有提供任何加密机制，通过在应用层实现SSL来保证UDP和TCP的安全性**

**进程寻址**：**IP地址**标识目标主机地址；**端口号**标识目标主机应用进程(因为每个应用进程对应一个套接字，即端口号也标识套接字)
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/appl_structure.jpg)

**应用层协议**定义了：运行在不同端系统上的应用进程如何相互交换报文:
- 交换的**报文类型**：请求和应答报文
- 各种报文类型的**语法**：报文中的各个字段及其描述
- 字段的**语义**：即字段取值的含义
- 进程何时、如何发送报文及对报文进行响应的**规则**

> 应用协议仅仅是应用的一个组成部分。如Web应用：HTTP协议，web客户端，web服务器，HTML


### Web 和 HTTP

**Web页**：由一些对象组成。对象可以是HTML文件、JPEG图像、Java小程序、声音剪辑文件等。Web页含有一个**基本的HTML文件**，该基本HTML文件又包含若干对象的引用（链接URL）。URL格式：

<div align=center>
   <img src="https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/http_url.jpg" width = "80%" height = "80%">
</div>


#### HTTP基础

HTTP是基于TCP传输协议的**超文本传输协议**。解释：**HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」**。

HTTP常见的状态码：
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/http_statue_code.jpg)

HTTP两种连接方式：
- **非持久HTTP** : 
  - 最多只有一个对象在TCP连接上发送
  - 下载多个对象需要多个TCP连接
  - HTTP/1.0使用非持久连接
  - 2RTT+传输时间（一个RTT发起TCP连接，一个用来HTTP请求，并等待HTTP响应）
- **持久HTTP** : 
  - 多个对象可以在一个（在客户端和服务器之间的）TCP连接上传输
  - HTTP/1.1 默认使用持久连接

<figure>
    <img src="https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/http_short_conn.jpg" width = "35%" height = "35%"/>
    <img src="https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/http_long_conn.jpg" width = "35%" height = "35%"/>
</figure>

> 持久连接与并行连接配合使用可能是最高效的方式


#### HTTP请求

HTTP 请求包括三部分，分别是**请求行**（请求方法）、**请求头**（消息报头）和**请求正文**。HTTP 请求第三行为请求正文，请求正文是可选的，它最常出现在 post 请求方式中，get 请求无正文，所以回车之后为空。示例如下：
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/http_request.png)

**请求行**

请求行由三部分构成：第一部分说明请求类型为 get 方法请求，第二部分（用/分开）是资源 URL，第三部分说明使用的是 HTTP1.1 版本.
``GET /success.txt HTTP/1.1\r\n``
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/http_request_way.png)

其中用得最多的方法是 **get 方法和 post 方法**。根据 RFC 规范，**GET 的语义是从服务器获取指定的资源**，这个资源可以是静态的文本、页面、图片视频等。根据 RFC 规范，**POST 的语义是根据请求负荷（报文body）对指定的资源做出处理**，具体的处理方式视资源类型而不同。POST 请求携带数据的位置一般是写在报文 body 中。
二者的**区别**：
1. get 直接在浏览器输入，post 需要工具发送请求；
2. get 用 url 或者 cookie 传参，post 将数据放在 body 中；
3. get 的 URL 有长度限制，post 数据可以非常大；
4. post 比 get 安全，因为 URL 看不到数据；
5. get 用来获取数据，post 用来发送数据。

**QUESTION: GET 和 POST 方法都是安全和幂等的吗？**
> 在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。
> 所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。

如果从 RFC 规范定义的语义来看：
- **GET 方法就是安全且幂等的**，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。所以，**可以对 GET 请求的数据做缓存**，这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（nginx），而且在浏览器中 GET 请求可以保存为书签。(安全、幂等、可被缓存)
- POST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是**不安全**的，且多次提交数据就会创建多个资源，所以**不是幂等**的。所以，浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签。(不安全、不幂等、不可缓存)
> 实际中，开发者可以不按RFC规范，GET也可以带body, POST的body也可以为空

**首部行**

首部行包含（客户机请求的服务器主机名，客户机的环境信息等）。具体内容及含义如下：
- ``Accept``：用于告诉服务器，客户机支持的数据类型 （例如：Accept:text/html,image/*）；
- ``Accept-Charset``：用于告诉服务器，客户机采用的编码格式；
- ``Accept-Encoding``：用于告诉服务器，客户机支持的数据压缩格式；``Accept-Encoding: gzip, deflate``
- ``Accept-Language``：客户机语言环境；
- ``Host``：客户端发送请求时，用来指定服务器的域名。可以请求同一服务器的不同网站
- ``If-Modified-Since``：客户机通过这个头告诉服务器，资源的缓存时间；
- ``Referer``：客户机通过这个头告诉服务器，它（客户端）是从哪个资源来访问服务器的（防盗链）；
- ``User-Agent``：客户机通过这个头告诉服务器，客户机的软件环境（操作系统，浏览器版本等）；
- ``Cookie``：客户机通过这个头，将 Coockie 信息带给服务器；
- ``Connection``：客户端要求服务器使用「HTTP 长连接」机制。``Connection: Keep-Alive``。**HTTP/1.1 版本的默认连接都是长连接**，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。但为了兼容老版本的 HTTP，需要指定 Connection 首部字段的值为 Keep-Alive。若关闭：``Connection: close``。
- ``Date``：告诉服务器，当前请求的时间。

**空行**
首部行后面的包含回车、换行符号的“空行”

**实体体**(entity body)

浏览器端通过 HTTP 协议发送给服务器的实体数据。get 请求时，body为空。post 请求时，通过表单发送给服务器的值，也可以为空。

#### HTTP响应

一个 HTTP 响应代表服务器端向客户端回送的数据，它包括：一个状态行，若干个首部行，以及实体内容。示例如下：
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/http_response.png)
**状态行**
包括 HTTP 版本HTTP/1.1，状态码200，以及消息OK;
 
**首部行**
响应头有若干个字段组合（根据具体情况选择），常见字段及其含义如下：
- ``Content-Type``：服务器给客户端传回来的文件格式;```Content-Type: text/html; Charset=utf-8```。与客户端请求的``Accept``对应。
- ``Content-Encoding``: 服务器返回的数据使用了什么压缩格式。``Content-Encoding: gzip``
- ``Content-Length``：服务器返回数据时表明本次回应的数据长度，``Content-Length: 1000``。**HTTP 协议通过设置回车符、换行符作为 HTTP header 的边界，通过 Content-Length 字段作为 HTTP body 的边界，这两个方式都是为了解决“粘包”的问题**。
- ``Last-Modified``：文档的最后改动时间；
- ``ETag``：这个响应头中有种Weak Tag，值为W/“xxxxx”。它声明Tag是弱匹配的，只能做模糊匹配，在差异达到一定阈值时才起作用；
- ``Accept-Ranges``：表示该服务器是否支持文件的范文请求；
- ``Server``：设置服务器名称；
- ``Date``：当前 GMT 时间，这个就是你请求的东西被服务器创建的时间。

**空行**
首部行后面的包含回车、换行符号的“空行”

**实体体**
响应包含浏览器能够解析的静态内容，例如：HTML，纯文本，图片等等信息。

#### HTTP缓存
HTTP缓存分为**强缓存**和**协商缓存**。整体流程如下：

![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/http_cache2.png)
**协商缓存这两个字段都需要配合强制缓存中 Cache-Control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求**。

##### 强缓存

强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。强缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期：
- ``Cache-Control``: 是一个相对时间；
- ``Expires``:是一个绝对时间；
> Cache-Control 的优先级高于 Expires 。

使用 Cache-Control 来实现强缓存流程如下：
- 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小；
- 浏览器再次请求访问服务器中的该资源时，会先**通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期**，如果没有，则使用该缓存，否则重新请求服务器；
- 服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。

##### 协商缓存

协商缓存就是与服务端协商之后，通过协商结果来判断是否使用本地缓存。

**Last-Modified/If-Modified-Since**
``Last-Modified/If-Modified-Since``的值是资源修改时间。第一次请求资源时，服务端将资源的**最后修改时间**放到响应头的 ``Last-Modified`` 字段中，第二次请求该资源时，浏览器会自动将该资源上一次响应头中的``Last-Modified``的值放到第二次请求头的``If-Modified-Since``字段中，服务端比较服务端资源的最后一次修改时间和请求头中的 ``If-Modified-Since`` 的值，如果相等，则命中缓存返回 304，否则，返回200。
**ETag/If-None-Match**
``ETag/If-None-Match`` 的值是一串hash值（hash算法不统一），是资源的标识符，当资源内容发生变化，其hash值也会改变。第一次请求资源时，服务端将资源的哈希值放到响应头的 ``ETag`` 字段中，第二次请求该资源时，浏览器会自动将该资源上一次响应头中的``ETag``的值放到第二次请求头的``If-None-Match``字段。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。
> ETag/If-None-Match优先级比Last-Modified/If-Modified-Since高；
> Last-Modified/If-Modified-Since有个1S问题，即服务端在1S内修改文件，且再次受到请求时，会错误的返回304。

**参考：**
- [一文读懂HTTP缓存机制](https://blog.csdn.net/sinat_36521655/article/details/106221905)

#### HTTP比较

HTTP是无状态、明文传输的。对于无状态问题，简单方法使用Cookie。对于安全问题，可以用HTTPS的方式解决，也就是通过引入SSL/TLS层。

![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/http_cmp.jpg)

**HTTP/1.1相比HTTP/1.0性能上的改进**：
1. 使用TCP长连接的方式改善了HTTP/1.0短连接造成性能开销
2. 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间

**HTTP/1.1 自身的性能瓶颈**：
1. 请求/响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩Body的部分
2. 发送冗长的首部。每次互相发送相同的首部造成的浪费较多
3. 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞
4. 没有请求优先级控制
5. 请求只能从客户端开始，服务器只能被动响应

**HTTP/1.1协议优化**：
1. 通过缓存技术来避免发送 HTTP 请求
2. 减少 HTTP 请求的次数
   - 减少重定向请求次数；
   - 合并请求；
   - 延迟发送请求；
3. 减少 HTTP 响应的数据大小
   - 无损压缩
   - 有损压缩 

**HTTP 与 HTTPS 的区别**
1. HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
2. HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程(**四次握手**)，才可进入加密报文传输。
3. 两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。
4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

**HTTPS 协议本身到目前为止还是没有任何漏洞的，即使你成功进行中间人攻击，本质上是利用了客户端的漏洞（用户点击继续访问或者被恶意导入伪造的根证书），并不是 HTTPS 不够安全。**

HTTP/2协议是基于HTTPS的，所以HTTP/2的安全性是有保障的。

**HTTP/2相比HTTP/1.1性能上的改进**：
1. HTTP/2会**头部压缩**（Header），如果你同时发送多个请求，他们的头是一样的或者是相似的，那么协议会帮你消除重复的部分。
2. HTTP/2不再像HTTP/1.1里的纯文本的报文，而是全面采用了**二进制格式**。头信息和数据体都是二进制，并且统称为帧（frame）：头信息帧和数据帧。
3. HTTP/2的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。客户端还可以指定数据流的优先级。
4. HTTP/2的连接可以**并发多个请求**（多路复用），而不用按照顺序一一对应。移除了HTTP/1.1中的串行请求，不需要排队等待，不会再出现「队头阻塞」问题。比如：在一个TCP连接里，服务器收到了客户端A和B的两个请求，如果发现A处理过程非常耗时，于是就回应A请求已经处理好的部分，接着回应B请求，完成后，再回应A请求剩下的部分。
5. 服务器推送，HTTP/2在一定程度上改善了传统的「请求-应答」工作模式，服务不再是被动地响应，也可以**主动向客户端发送消息**。

**HTTP/3**:
面我们知道了 HTTP/1.1 和 HTTP/2 都有队头阻塞的问题：
- HTTP/1.1 中的管道（ pipeline）虽然解决了请求的队头阻塞，但是**没有解决响应的队头阻塞**，因为服务端需要按顺序响应收到的请求，如果服务端处理某个请求消耗的时间比较长，那么只能等响应完这个请求后， 才能处理下一个请求，这属于 HTTP 层队头阻塞。
- HTTP/2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞，但下层的TCP协议是不知道有多少个HTTP请求。所以**一旦发生了丢包**现象，就会触发TCP的重传机制，这样在一个TCP连接中的所有的HTTP请求都必须等待这个丢了包被重传回来（**阻塞住所有的 HTTP 请求**）。

HTTP/2 队头阻塞的问题是因为 TCP，所以 **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP**！基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。QUIC 有 3 个特点：**无队头阻塞**， **建立连接速度快**，**连接迁移**

### DNS


域名系统（英语：Domain Name System，缩写：DNS）是互联网的一项服务。它作为**将域名和IP地址相互映射的一个分布式数据库**，能够使人更方便地访问互联网。DNS使用TCP和UDP端口53。当前，对于每一级域名长度的限制是63个字符，域名总长度则不能超过253个字符。

> 本地域名服务器如 114.114.114.114 / 8.8.8.8

#### DNS的工作原理
1. 客户端向离它最近的DNS服务器发起了查询请求，一般是由运营商提供
2. 如果代理DNS服务器有记录则直接可以返回给客户端；如果没有记录则去根DNS服务器请求，根DNS并不会存储所以的主机名对应IP的记录，它只会记录它的子域的IP，例如`.com`等后缀的域，代理DNS服务器会拿到`.com`域的DNS服务器IP
3. 然后再将请求发往`.com.`域的DNS服务器，如果还是没有找到主机，则再往它的下一级找，直到找到具体的主机，把IP返回给客户端，同时代理DNS服务器也会缓存一份到本地

一次完整的查询请求经过的流程：Client -->hosts文件 -->DNS Service Local Cache --> DNS Server (recursion) --> Server Cache --> iteration(迭代) --> 根--> 顶级域名DNS-->二级域名DNS…
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/dns.png)

#### DNS域名结构
- 根域：目前有13个根集群服务器，美国10台，日本1台，荷兰1台，瑞典1台
- 一级域名：Top Level Domain: tld com, edu, mil, gov, net, org, int,arpa 组织域、国家域(.cn, .ca, .hk, .tw)、反向域 等
- 二级域名
- 三级域名
- 最多127级域名

ICANN（The Internet Corporation for Assigned Names and Numbers）互联网名称与数字地址分配机构，负责在全球范围内对互联网通用顶级域名（gTLD）以及国家和地区顶级域名（ccTLD）系统的管理、以及根服务器系统的管理
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/dns2.png)



#### DNS服务
DNS的实现：bind（Bekerley Internat Name Domain ） ，由 ISC （www.isc.org） 维护，配置实例的bind版本为 ：`bind-9.9.4-61.el7.x86_64`
软件包名：`bind`
服务名：`named`
提供的服务：`DNS域名解析`
主配置文件：`/etc/named.conf`

**参考：**
- [DNS](https://www.cnblogs.com/L-dongf/p/9118111.html)

## 运输层
运输层位于应用层和网络层之间，**为运行在不同主机上的应用进程之间提供逻辑通信**， 而网络层**提供了主机之间的逻辑通信**。运输层协议在端系统而不是在路由器中实现：
- 发送方：将应用层的报文分成报文段，然后传递给网络层
- 接收方：将报文段重组成报文，然后传递给应用层

有多个传输层协议供选择：TCP(**面向连接、可靠的、字节流**数据传输协议)/UDP(**无连接、不可靠、包**数据传输协议)

### 多路复用与多路分解
一个应用进程有一个或多个套接字。
在发送方主机**多路复用**：多个套接字接收来自多个进程的报文，根据套接字对应的IP地址和端口号等信息对报文段用头部加以封装 (该头部信息用于以后的解复用)
在接收方主机**多路分解**：根据报文段的头部信息中的IP地址和端口号将接收到的报文段发给正确的套接字(和对应的应用进程)。

**UDP多路分解**
在接收端，UDP套接字用二元组标识 (**目标IP地址、目标端口号**)。如果两个不同源IP地址/源端口号的数据报，但是有**相同的目标IP地址和端口号**，则被定位到相同的套接字。

**TCP多路分解**
在接收端，TCP套接字用二元组标识 (**源IP地址、源端口号、目的IP地址、目的端口号**)。接收主机用这四个值来将数据报定位到合适的套接字，能够在**一个TCP端口上同时支持多个TCP套接字**。

> C/S模式下持续HTTP，在整个连接期间，CS之间使用同一个套接字交换HTTP报文；C/S模式下非持续HTTP，每一对连接请求/响应创建新的套接字并在随后关闭。

### UDP基础

![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/udp_message_format.png)
伪首部的特点:
1. 长度为12Bytes
2. 伪首部不是UDP的真正首部，只在计算校验和时用到
3. 伪首部既不向下传送也不向上递交，只是为了计算校验和

UDP使用优点：
1. 无须连接建立（会增加延时）
2. 在发送端和接收端没有连接状态
3. 报文段的头部很小(开销小)
4. 无拥塞控制和流量控制（UDP可以尽可能快的发送报文段）
5. 发送什么数据以及何时发送的应用层控制更为精细

UDP校验和提供了差错检测功能，但无差错恢复能力

### TCP基础
TCP报文段格式如下：
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/tcp_message_format.png)
20bytes固定头部长度及余下最多40bytes的可变长度

- **序列号**：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小(可以在客户端发送，也可以在服务端发送)。**用来解决网络包乱序问题**。
- **确认应答号**：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。**用来解决丢包的问题**。
- 数据偏移字段： TCP 首部长度（Header Length）：数据偏移是指数据段中的“数据”部分起始处距离 TCP 数据段起始处的字节偏移量，占 4 位。其实这里的“数据偏移”也是在确定 TCP 数据段头部分的长度，告诉接收端的应用程序，数据从何处开始。
- **控制位**：
  - ACK：该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 ``SYN`` 包之外该位必须设置为 1 。
  - RST：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接，然后重新连接。
  - SYN：该位为 1 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。
  - FIN：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 FIN 位为 1 的 TCP 段
  >其中，ACK 是可能与 SYN，FIN 等同时使用的，比如 SYN 和 ACK 可能同时为 1 ，它表示的就是建立连接之后的响应， 如果只是单个的一个 SYN ，它表示的只是建立连接。（ TCP 的几次握手就是通过这样的 ACK 表现出来的）， 但 SYN 与 FIN 是不会同时为 1 的，因为前者表示的是建立连接，而后者表示的是断开连接。RST 一般是在 FIN 之后才会出现为 1 的情况，表示的是连接重置。一般地，当出现 FIN 包或 RST 包时，我们便认为客户端与服务器端断开了连接；而当出现 SYN 和 SYN＋ACK 包时，我们认为客户端与服务器建立了一个连接

**UDP 和 TCP 的区别**：
1. 连接
   - TCP 是面向连接的传输层协议，传输数据前先要建立连接。
   - UDP 是不需要连接，即刻传输数据。
2. 服务对象
   - TCP 是一对一的两点服务，即一条连接只有两个端点。
   - UDP 支持一对一、一对多、多对多的交互通信
3. 可靠性
   - TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达。
   - UDP 是尽最大努力交付，不保证可靠交付数据。但是我们可以基于 UDP 传输协议实现一个可靠的传输协议，比如 QUIC 协议
4. 拥塞控制、流量控制
   - TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。
   - UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。
5. 首部开销
   - TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。
   - UDP 首部只有 8 个字节，并且是固定不变的，开销较小。
6. **传输方式**
   - TCP 是流式传输，没有边界，但保证顺序和可靠。
   - UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。
7. 分片不同
   - TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。
   - UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。

**UDP 和 TCP 传输方式与粘包**
- 当用户消息通过 UDP 协议传输时，**操作系统不会对消息进行拆分**，在组装好 UDP 头部后就交给网络层来处理，所以发出去的 UDP 报文中的数据部分就是完整的用户消息，也就是**每个 UDP 报文就是一个用户消息的边界**，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息。
- 当用户消息通过 TCP 协议传输时，**消息可能会被操作系统分组成多个的 TCP 报文**，也就是一个完整的用户消息被拆分成多个 TCP 报文进行传输, 因此 TCP 是面向字节流的协议。可能造成TCP粘包，<font color=Red>TCP粘包就是指发送方发送的若干包数据到达接收方时粘成了一包，从接收缓冲区来看，后一包数据的头紧接着前一包数据的尾，出现粘包的原因是多方面的，可能是来自发送方，也可能是来自接收方</font>。如何解决TCP粘包问题：
  - 固定长度的消息；
  - 特殊字符作为边界；
  - 自定义消息结构。


**TCP 和 UDP 应用场景**：
- TCP应用场景： ``HTTP, FTP``
- UDP 应用场景：``DNS, SNMP``

> UDP 头部没有「首部长度」字段，TCP 头部有「首部长度」字段(因为UDP头部固定，TCP头部可变)
> UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段（仅有首部长度）
> **TCP/UDP 各自的端口号相互独立，TCP 和 UDP 可以使用同一个端口号**(因为可以通过IP包头区分不同协议类型)

### TCP三次挥手和四次握手
TCP三次挥手是连接建立过程，四次握手是连接断开过程。TCP连接建立及连接断开状态如下：
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/tcp_state.png)

#### TCP三次挥手

<div align=center>
   <img src="https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/tcp_connection.png" width = "70%" height = "70%">
</div>

TCP正常三次握手过程：
1. 一开始，客户端和服务端都处于 CLOSE 状态。先是服务端主动监听某个端口，处于 ``LISTEN`` 状态
2. 客户端会随机初始化序号（``x``），将此序号置于 TCP 首部的「序号」字段中，同时把 ``SYN`` 标志位置为 1，表示 SYN 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 ``SYN-SENT`` 状态。
3. 服务端收到客户端的 ``SYN`` 报文后，首先服务端也随机初始化自己的序号（``y``），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 ``x + 1``, 接着把 ``SYN`` 和 ``ACK`` 标志位置为 1。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 ``SYN-RCVD`` 状态。
4. 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 ``ACK`` 标志位置为 1 ，其次「确认应答号」字段填入 ``y + 1``，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 ``ESTABLISHED`` 状态。
5. 服务端收到客户端的应答报文后，也进入 ``ESTABLISHED`` 状态。

**为什么是三次握手？不是两次、四次？**
比较片面回答是：因为三次握手才能保证双方具有接收和发送的能力。
从三个方面分析原因：
1. **三次握手才能防止旧的重复连接初始化造成混乱**（主要原因）
   - 如果连接过程中，客户端发起 SYN， 服务器收到后，客户机离线了；客户机上线后再次发送SYN(此时服务器先后收到旧SYN、新SYN), 服务器 ack 报文并不是确认收到「新 SYN 报文」的，而是上一次的 ack 确认号（**Challenge Ack**），此时客户端收到错误的 ACK 和 SYN，发送RST。
   - **如果是两次握手连接，就无法阻止历史连接**, 主要是因为**在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，不仅导致服务端可能建立一个历史连接，而且造成资源浪费**。
2. **同步双方初始序列号**
   - TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用：
      - 接收方可以去除重复的数据；
      - 接收方可以根据数据包的序列号按序接收；
      - 可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；
   - **两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收**。**四次握手也能同步双方初始序列号**，但三次握手足矣
3. **避免资源浪费** 
   - 如果只有「两次握手」，客户端发送的 SYN 报文在网络中阻塞了，重复发送多次 SYN 报文，那么**服务端每次在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费**。 

**每次建立 TCP 连接时，初始化的序列号都要求不一样**
主要原因有两个方面：
1. 为了**防止历史报文被下一个相同四元组的连接接收**（主要方面）；
2. 为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；

**如何使得每次初始化的序列号都不一样以避免历史报文？**
RFC793 提到初始化序列号 ISN 随机生成算法：ISN = M + F(localhost, localport, remotehost, remoteport)。
- M是一个计时器，这个计时器每隔 4 微秒加1。
- F 是一个 Hash 算法，根据源IP、目的IP、源端口、目的端口生成一个随机数值，要保证 hash 算法不能被外部轻易推算得出。

可以看到，随机数是会基于时钟计时器递增的，基本不可能会随机成一样的**初始化序列号(ISN)**，但还是不能完全避免了。**序列号**(SEQ)是一个 32 位的无符号数，不断递增，在到达 4G 之后再循环回到 0。
因此可以得到，**序列号和初始化序列号并不是无限递增的，会发生回绕为初始值的情况，这意味着无法根据序列号来判断新老数据**。为了解决这个问题，就需要有 **TCP 时间戳**。tcp_timestamps 参数是默认开启的，开启了 tcp_timestamps 参数，TCP 头部就会使用时间戳选项，它有两个好处，**一个是便于精确计算 RTT ，另一个是能防止序列号回绕（PAWS）**。

**既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？**
介绍 MTU 和 MSS：
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/MTU_MSS.png)
如果在 TCP 的整个报文（头部 + 数据）交给 IP 层进行分片，当 IP 层有一个超过 MTU 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成若干片，保证每一个分片都小于 MTU。把一份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后，再交给上一层 TCP 传输层。由于IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。因此，**当如果一个 IP 分片丢失**，**就会重发「整个 TCP 报文（头部 + 数据）」，即整个 IP 报文的所有分片都得重传**(以MTU为单位重发)。 IP 层进行分片传输，是非常没有效率的。
为了达到最佳的传输效能 TCP 协议在**建立连接的时候通常要协商双方的 MSS 值**，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU，也就不用 IP 分片了。经过 TCP 层分片后，如果一个 TCP 分片丢失后，**进行重发时也是以 MSS 为单位**，而不用重传所有的分片，大大增加了重传的效率。

**第一次握手丢失了，会发生什么？**
客户端首先发送 ``SYN`` 报文，然后进入 ``SYN_SENT``状态，如果客户端迟迟收不到 ``SYN-ACK``报文(第二次握手)，就会触发**超时重传**机制，重传SYN报文，并且**重传的SYN报文的序列号都是一样的**。如果超过客户端的 SYN 报文最大重传次数(``tcp_syn_retries``)有限制，客户端还没收到``SYN-ACK``报文，就会自动断开TCP连接

**第二次握手丢失了，会发生什么？**
当第二次握手丢失了，客户端和服务端都会重传（超过对应重传次数，格各自断开对应的TCP连接）：
- 客户端会重传 SYN 报文，也就是第一次握手，最大重传次数由 ``tcp_syn_retries``内核参数决定；
- 第二次握手丢失了，服务端就收不到第三次握手，于是**服务端这边会触发超时重传机制，重传 SYN-ACK 报文**。最大重传次数由 ``tcp_synack_retries`` 内核参数决定。

**第三次握手丢失了，会发生什么？**
客户端收到服务端的 ``SYN-ACK`` 报文后，就会给服务端回一个 ``ACK`` 报文，也就是第三次握手，此时客户端状态进入到 ``ESTABLISH`` 状态。当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，**重传 SYN-ACK 报文**，直到收到第三次握手，或者达到最大重传次数服务器断开TCP连接。

**TCP 半连接队列和全连接队列，SYN泛洪攻击以及如何避免SYN泛洪攻击？**
在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：
- 半连接队列，也称 SYN 队列；
- 全连接队列，也称 accept 队列；
> 半连接队列其实被设计成了哈希表，而全连接队列本质是链表。
> **每一个socket执行listen时，内核都会自动创建一个半连接队列和全连接队列**

服务端收到客户端发起的 SYN 请求后，**内核会把该连接存储到半连接队列**，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，**内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来**。

![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/tcp_connection_syn_accept_deque.jpg)

> 不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，内核会直接丢弃，或返回 RST 包。

SYN 攻击方式最直接的表现就是伪造不同 IP 地址的 SYN 报文，**当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃**，导致客户端无法和服务端建立连接。

避免 SYN 攻击方式，可以有以下四种方法：
- 调大 netdev_max_backlog；
- 增大 TCP 半连接队列:需同时增大下面这三个参数：
  - 增大 net.ipv4.tcp_max_syn_backlog
  - 增大 listen() 函数中的 backlog
  - 增大 net.core.somaxconn
- 开启 tcp_syncookies: 开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接，相当于绕过了 SYN 半连接来建立连接。
- 减少 SYN+ACK 重传次数: 减少 SYN-ACK 的重传次数，以加快处于 SYN_REVC 状态的 TCP 连接断开。

**没有 accept，能建立 TCP 连接吗？**
答案是**可以的**。accpet 系统调用并不参与 TCP 三次握手过程，它只是负责从 TCP 全连接队列取出一个已经建立连接的 socket，用户层通过 accpet 系统调用拿到了已经建立连接的 socket，就可以对该 socket 进行读写操作了。

**没有 listen，能建立 TCP 连接吗？**
是可以的，客户端是可以自己连自己的形成连接（**TCP自连接**），也可以两个客户端同时向对方发出请求建立连接（**TCP同时打开**），这两个情况都有个共同点，就是没有**服务端参与，也就是没有listen，就能建立连接**。原因是：**客户端没有半连接队列和全连接队列，但有一个全局hash，可以通过它实现自连接或TCP同时打开**。
比如，在 TCP 自连接的情况中，客户端在 connect 方法时，最后会将自己的连接信息放入到这个全局 hash 表中，然后将信息发出，消息在经过回环地址重新回到 TCP 传输层的时候，就会根据 IP + 端口信息，再一次从这个全局 hash 中取出信息。于是握手包一来一回，最后成功建立连接。


>针对一个问题的回答：**服务端如果只 bind 了 IP 地址和端口，而没有调用 listen 的话，然后客户端对服务端发起了连接建立，服务端会回 RST 报文**。

#### TCP四次挥手

<div align=center>
   <img src="https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/tcp_disconnection.png" width = "70%" height = "70%">
</div>
TCP正常四次挥手过程：

1. 客户端打算关闭连接，此时会发送一个 TCP 首部 ``FIN`` 标志位被置为 ``1`` 的报文，也即 ``FIN`` 报文，之后客户端进入 ``FIN_WAIT_1`` 状态。
2. 服务端收到该报文后，就向客户端发送 ``ACK`` 应答报文，接着服务端进入 ``CLOSE_WAIT`` 状态。
3. 客户端收到服务端的 ``ACK`` 应答报文后，之后进入 ``FIN_WAIT_2`` 状态。
4. 等待服务端处理完数据后，也向客户端发送 ``FIN`` 报文，之后服务端进入 ``LAST_ACK`` 状态。
5. 客户端收到服务端的 ``FIN`` 报文后，回一个 ``ACK`` 应答报文，之后进入 ``TIME_WAIT`` 状态
6. 服务端收到了 ``ACK`` 应答报文后，就进入了 ``CLOSE`` 状态，至此服务端已经完成连接的关闭。
7. 客户端在经过 2``MSL``(Maximum Segment Lifetime) 一段时间后，自动进入 ``CLOSE`` 状态，至此客户端也完成连接的关闭。

每个方向都需要**一个 FIN 和一个 ACK**，因此通常被称为**四次挥手**。

**为什么需要 TCP 四次挥手，可以变成三次吗？**
关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。服务端收到客户端的 FIN 报文时，先回一个 ACK 应答报文，**而服务端可能还有数据需要处理和发送，等服务端不再发送数据时**，才发送 FIN 报文给客户端来表示同意现在关闭连接。客户端还要发送应答 ACK。所以需要四次挥手。
服务器 ACK 客户端 FIN 过程中(第二次握手)，，**「没有数据要发送」并且「开启了 TCP 延迟确认机制（默认会开启）」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手**。
> TCP 延迟确认机制: 
> - 当服务器有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方
> - 当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送
> - 如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK，如果没有数据需要发送，超过延迟设定时间，也发送 ACK。

![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/tcp_disconnect_ack_fin.jpg)

**粗暴关闭 vs 优雅关闭**
 TCP 四次挥手的时候，关闭的连接的函数有两种函数：
- close 函数，同时 socket 关闭发送方向和读取方向，也就是 socket 不再有发送和接收数据的能力。如果有多进程/多线程共享同一个 socket，如果有一个进程调用了 close 关闭只是让 socket 引用计数 -1，并不会导致 socket 不可用，同时也不会发出 FIN 报文，其他进程还是可以正常读写该 socket，直到引用计数变为 0，才会发出 FIN 报文。
- shutdown 函数，可以指定 socket 只关闭发送方向而不关闭读取方向，也就是 socket 不再有发送数据的能力，但是还是具有接收数据的能力。如果有多进程/多线程共享同一个 socket，shutdown 则不管引用计数，直接使得该 socket 不可用，然后发出 FIN 报文，如果有别的进程企图使用该 socket，将会受到影响。
  
如果客户端是用 close 函数来关闭连接，那么在 TCP 四次挥手过程中，如果收到了服务端发送的数据，由于客户端已经不再具有发送和接收数据的能力，所以客户端的内核会回 RST 报文给服务端，然后内核会释放连接，这时就不会经历完成的 TCP 四次挥手，所以我们常说，调用 close 是粗暴的关闭。当服务端收到 RST 后，内核就会释放连接。
相对的，shutdown 函数因为可以指定只关闭发送方向而不关闭读取方向，所以即使在 TCP 四次挥手过程中，如果收到了服务端发送的数据，客户端也是可以正常读取到该数据的，然后就会经历完整的 TCP 四次挥手，所以我们常说，调用 shutdown 是优雅的关闭。shutdown 函数也可以指定「只关闭读取方向，而不关闭发送方向」，但是这时候内核是不会发送 FIN 报文的。


**第一次挥手丢失了，会发生什么？**
客户端首先发送 ``FIN`` 报文，然后进入 ``FIN_WAIT_1``状态，如果第一次挥手丢失了，那么客户端迟迟收不到 ``ACK``报文(第二次挥手)，就会触发**超时重传**机制，重传 FIN 报文，重发次数由 ``tcp_orphan_retries`` 参数控制。超过最大重传次数还没收到``ACK``报文，就会自动断开TCP连接。

**第二次挥手丢失了，会发生什么？**
当服务端收到客户端的第一次挥手后，就会先回一个 ACK 确认报文，此时服务端的连接进入到 CLOSE_WAIT 状态。**ACK 报文是不会重传的**，所以如果服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数(``tcp_orphan_retries``)。

**第三次挥手丢失了，会发生什么？**
服务端内核自动回复 ACK 后，必须由进程主动调用 close 函数来触发内核发送 FIN 报文。同时连接进入 LAST_ACK 状态，等待客户端返回 ACK 来确认连接关闭。
如果迟迟收不到这个 ACK，服务端就会重发 FIN 报文，重发次数仍然由 ``tcp_orphan_retries`` 参数控制，这与客户端重发 FIN 报文的重传次数控制方式是一样的。

客户端因为是通过 close 函数关闭连接的，处于 FIN_WAIT_2 状态是有时长限制的，如果 tcp_fin_timeout 时间内还是没能收到服务端的第三次挥手（FIN 报文），那么客户端就会断开连接。

**第四次挥手丢失了，会发生什么？**
当客户端收到服务端的第三次挥手的 FIN 报文后，就会回 ACK 报文，也就是第四次挥手，此时客户端连接进入 ``TIME_WAIT`` 状态。TIME_WAIT 状态会持续 2MSL 后才会进入关闭状态。如果第四次挥手的 ACK 报文没有到达服务端，服务端就会重发 FIN 报文，重发次数仍然由前面介绍过的 ``tcp_orphan_retries`` 参数控制。超过最大传输次数，服务器还没收到第四次挥手，就会关闭服务器TCP。

**为什么 TIME_WAIT 等待的时间是 2MSL？**
TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以一来一回**需要等待 2 倍的时间**。

**为什么需要 TIME_WAIT 状态？**
主动发起关闭连接的一方，才会有 TIME-WAIT 状态。需要 TIME-WAIT 状态，主要是两个原因：
- 为了防止历史连接中的数据，被后面相同四元组的连接错误的接收，因此 TCP 设计了 TIME_WAIT 状态，状态会持续 2MSL 时长，这个时间**足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的**。
- 保证「被动关闭连接」的一方，能被正确的关闭。TIME-WAIT 作用是**等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭**。

**TIME_WAIT 过多有什么危害？**
- 第一是占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等；
- 第二是占用端口资源，端口资源也是有限的，一般可以开启的端口为 32768～61000，也可以通过 ``net.ipv4.ip_local_port_range`` 参数指定范围。

**TCP保活机制**: 定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。**对端进程崩溃后操作系统在回收进程资源的时候，会发送 FIN 报文，而对端主机宕机则是无法感知的，所以需要 TCP 保活机制来探测对方是不是发生了主机宕机**。
> - HTTP 的 Keep-Alive，是由应用层（用户态） 实现的，称为 HTTP 长连接；
> - TCP 的 Keepalive，是由 TCP 层（内核态） 实现的，称为 TCP 保活机制；

**进程崩溃和主机宕机(断电)的区别：**
如果「**客户端进程崩溃**」，客户端的进程在发生崩溃的时候，内核会发送 FIN 报文，与服务端进行四次挥手。
但是，「**客户端主机宕机**」（断电），那么是不会发生四次挥手的，具体后续会发生什么？还要看服务端会不会发送数据？
- 如果服务端会发送数据，由于客户端已经不存在，收不到数据报文的响应报文，服务端的数据报文会超时重传，当重传总间隔时长达到一定阈值（内核会根据 tcp_retries2 设置的值计算出一个阈值）后，会断开 TCP 连接；
  >**如果只要有一方重启完成后，收到之前 TCP 连接的报文，都会回复 RST 报文，以断开连接**。
- 如果服务端一直不会发送数据，再看服务端有没有开启 TCP keepalive 机制？
   - 如果有开启，服务端在一段时间没有进行数据交互时，会触发 TCP keepalive 机制，探测对方是否存在，如果探测到对方已经消亡，则会断开自身的 TCP 连接；
   - 如果没有开启，服务端的 TCP 连接会一直存在，并且一直保持在 ESTABLISHED 状态。

**拔掉网线后， 原本的 TCP 连接还存在吗？**
客户端拔掉网线后，并不会直接影响 TCP 连接状态。所以，拔掉网线后，TCP 连接是否还会存在，关键要看拔掉网线之后，有没有进行数据传输。
有数据传输的情况：
- 在客户端拔掉网线后，如果服务端发送了数据报文，那么在服务端重传次数没有达到最大值之前，客户端就插回了网线，那么双方原本的 TCP 连接还是能正常存在，就好像什么事情都没有发生。
- 在客户端拔掉网线后，如果服务端发送了数据报文，在客户端插回网线之前，服务端重传次数达到了最大值时，服务端就会断开 TCP 连接。等到客户端插回网线后，向服务端发送了数据，因为服务端已经断开了与客户端相同四元组的 TCP 连接，所以就会回 RST 报文，客户端收到后就会断开 TCP 连接。至此， 双方的 TCP 连接都断开了。
  
没有数据传输的情况：
- 如果双方都没有开启 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，那么客户端和服务端的 TCP 连接状态将会一直保持存在。
- 如果双方都开启了 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，TCP keepalive 机制会探测到对方的 TCP 连接没有存活，于是就会断开 TCP 连接。而如果在 TCP 探测期间，客户端插回了网线，那么双方原本的 TCP 连接还是能正常存在。

**参考：**
- [多图详解 TCP 连接管理](https://www.cnblogs.com/cxuanBlog/p/14679563.html)
- [TCP state transmissions](https://totozhang.github.io/2016-01-23-tcp-connection-status-transit/)





### TCP重传机制
TCP 实现可靠传输的方式之一，是通过序列号与确认应答。TCP 针对数据包丢失的情况，会用**重传机制**解决。

#### 超时重传
重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 ACK 确认应答报文，就会重发该数据，也就是我们常说的超时重传。TCP 会在以下两种情况发生超时重传：

- 数据包丢失
- 确认应答丢失

![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/tcp_retrans_tim1.jpg)

RTT 指的是数据发送时刻到接收到确认的时刻的差值，也就是包的往返时间。**超时重传时间是以 RTO （Retransmission Timeout）的值应该略大于报文往返 RTT 的值**。RTO比RTT小，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。RTO比RTT大重发就慢，丢了老半天才重发，没有效率，性能差。RTO计算如下：
```c
/* Given a new RTT measurement `RTT' */

if (RTT is the first measurement made on this connection) {
	SRTT    := RTT
	RTTVAR  := RTT / 2
	RTO	:= SRTT + max(G, 2 * RTT)	/* G is clock granularity in seconds */
} else {
	delta	:= RTT - SRTT
	SRTT'	:= SRTT  +  1/8 * delta
	RTTVAR' := 3/4 * RTTVAR  +  1/4 * |delta|
	RTO	:= SRTT' + max(G, 4 * RTTVAR')	
}
```
**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍**。两次超时，就说明网络环境差，不宜频繁反复发送。

#### 快速重传
快速重传（Fast Retransmit）机制，它**不以时间为驱动，而是以数据驱动重传**。快速重传的工作方式是**当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段**。
快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是重传的时候，**是重传一个，还是重传所有的问题**。


#### SACK 方法
还有一种实现重传机制的方式叫：SACK（ Selective Acknowledgment）， **选择性确认**。

这种方式需要在 TCP 头部「选项」字段里加一个 ``SACK`` 的东西，它可以**将已收到的数据的信息发送给「发送方」**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/tcp_selective_acknowledgment.jpg)

如果要支持 SACK，必须双方都要支持。在 Linux 下，可以通过 net.ipv4.tcp_sack 参数打开这个功能（Linux 2.4 后默认打开）。

#### Duplicate SACK
Duplicate SACK 又称 D-SACK，其主要使用了**SACK 来告诉「发送方」有哪些数据被重复接收了**。
<figure>
    <img src="https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/tcp_duplicate_sack.jpg" width = "75%" height = "75%"/>
    <img src="https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/tcp_duplicate_sack2.jpg" width = "80%" height = "80%"/>
</figure>

D-SACK 有以下好处：
- 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;
- 可以知道是不是「发送方」的数据包被网络延迟了;
- 可以知道网络中是不是把「发送方」的数据包给复制了;

在 Linux 下可以通过 net.ipv4.tcp_dsack 参数开启/关闭这个功能（Linux 2.4 后默认打开）。

### TCP滑动窗口

滑动窗口的引入也是为了效率，试想如果tcp在传输过程中，都是等到对方ack返回后才发下一个，明显效率就会很低。效率上，遇事不决，先引入缓存。**滑动窗口就是操作系统开辟的缓存空间，通过指定特定大小的滑动窗口，可以在窗口的范围内无须得到应答，就继续发送对端数据**。当收到应答，再把窗口中对应的数据清理掉。

**滑动窗口**解决的是**发送方和接收方接收数据速率不一致的问题**, 通过设置滑动窗口(可以通俗的理解为接收方的缓存)可以缓解这一个问题。具体的操作是接收方会向发送方通知自己可以接受数据的大小，而发送方会根据这个数值，发送数据。

另外滑动窗口传输数据采用**累计应答**的方式，这样可以降低重传的次数，提高传输效率。

![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/tcp_window.jpg)

**TCP滑动窗口大小的确认**
滑动窗口的大小一般由接收方(接收方发送 ``window`` 字段给发送方)决定可以接受多少，否则发送方发送太多也承接不了。

**发送方的滑动窗口**
发送窗口根据处理的情况分成四个部分，其中深蓝色方框是发送窗口，紫色方框是可用窗口：
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/tcp_window_send1.jpg)
- #1 是已发送并收到 ACK确认的数据：1~31 字节
- #2 是已发送但未收到 ACK确认的数据：32~45 字节
- #3 是未发送但总大小在接收方处理范围内（接收方还有空间）：46~51字节
- #4 是未发送但总大小超过接收方处理范围（接收方没有空间）：52字节以后

当发送方把数据「全部」都一下发送出去后，可用窗口的大小就为 0 了，表明可用窗口耗尽，在没收到 ACK 确认之前是无法继续发送数据了。

在下图，当收到之前发送的数据 32~36 字节的 ACK 确认应答后，如果发送窗口的大小没有变化，则**滑动窗口往右边移动 5 个字节，因为有 5 个字节的数据被应答确认**，接下来 52~56 字节又变成了可用窗口，那么后续也就可以发送 52~56 这 5 个字节的数据了。

![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/tcp_window_send2.jpg)

TCP 滑动窗口方案使用三个指针来跟踪在四个传输类别中的每一个类别中的字节。
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/tcp_window_send3.jpg)
- ``SND.WND``：表示发送窗口的大小（大小是由接收方指定的）；
- ``SND.UNA``（Send Unacknoleged）：是一个绝对指针，它指向的是已发送但未收到确认的第一个字节的序列号，也就是 #2 的第一个字节。
- ``SND.NXT``：也是一个绝对指针，它指向未发送但可发送范围的第一个字节的序列号，也就是 #3 的第一个字节。
- 指向 #4 的第一个字节是个相对指针，它需要 SND.UNA 指针加上 SND.WND 大小的偏移量，就可以指向 #4 的第一个字节了。

**可用窗口大小 = SND.WND -（SND.NXT - SND.UNA）**

**接收方的滑动窗口**
接收窗口根据处理的情况划分成三个部分，使用两个指针进行划分:
- #1 + #2 是已成功接收并确认的数据（等待应用进程读取）；
- #3 是未收到数据但可以接收的数据；
- #4 未收到数据并不可以接收的数据；
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/tcp_window_recv.jpg)
- ``RCV.WND``：表示接收窗口的大小，它会通告给发送方。
- ``RCV.NXT``：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号，也就是 #3 的第一个字节。
- 指向 #4 的第一个字节是个相对指针，它需要 RCV.NXT 指针加上 RCV.WND 大小的偏移量，就可以指向 #4 的第一个字节了。

> 接收窗口的大小是约等于发送窗口的大小的。


### TCP流量控制

**TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制**。

发送窗口和接收窗口中所存放的字节数，都是放在操作系统内存缓冲区中的，而操作系统的缓冲区，会**被操作系统调整**。

为了防止丢包这种情况发生，**TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，这样就可以避免了丢包情况**。

#### 窗口关闭
如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。接收方向发送方通告窗口大小时，是通过 ACK 报文来通告的。如果这个通告窗口的 ACK 报文在网络中丢失了，那麻烦就大了。

为了解决窗口关闭时，潜在的死锁现象呢，TCP 为每个连接设有一个持续定时器，**只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器**。如果持续计时器超时，就会发**送窗口探测** ( Window probe ) 报文，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/tcp_window_recv2.jpg)

#### 糊涂窗口综合症

如果**接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症**。

要解决糊涂窗口综合症，就要同时解决上面两个问题就可以了：
- 让接收方不通告小窗口给发送方
  - 当「窗口大小」小于 min( MSS，缓存空间/2 ) ，也就是小于 MSS 与 1/2 缓存大小中的最小值时，就会向发送方通告窗口为 0，也就阻止了发送方再发数据过来。
- 让发送方避免发送小数据
  - 开启 Nagle 算法(默认开启)，Nagle 伪代码如下：
   ```cpp
   if 有数据要发送 {
      if 可用窗口大小 >= MSS and 可发送的数据 >= MSS {
    	   立刻发送MSS大小的数据
      } else {
         if 有未确认的数据 {
            将数据放入缓存等待接收ACK
         } else {
            立刻发送数据
         }
      }
   }
   ```
 
### TCP拥塞控制

通过控制 TCP 「发送方」的数据量来避免IP网络的拥塞，这就是**拥塞控制**。

造成拥塞的原因
- 多条流入线路有分组到达，并需要同一输出线路，此时，如果路由器没有足够的内存来存放所有这些分组，那么有的分组就会丢失；
- 路由器的慢带处理器的缘故，以至于难以完成必要的处理工作，如缓冲区排队、更新路由表等。

防止拥塞的方法
- 在传输层可采用重传策略、乱序缓存策略、确认策略、流控制策略和确定超时策略；
- 在网络层可采用子网内部的虚电路与数据报策略、分组排队和服务策略、分组丢弃策略、路由算法和分组生存管理；
- 在数据链路层可采用重传策略、乱序缓存策略、确认策略和流控制策略。

**拥塞窗口** cwnd 是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**。拥塞窗口 cwnd 变化的规则：
- 只要网络中没有出现拥塞，cwnd 就会增大；
- 但网络中出现了拥塞，cwnd 就减少；

发送窗口的值是拥塞窗口和接收窗口中的最小值，即 **swnd = min(cwnd, rwnd)**

判断当前网络是否出现拥塞：其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是**发生了超时重传，就会认为网络出现了拥塞**。

以下详细介绍四种拥塞控制算法。
#### 慢启动
慢启动是一点一点的提高发送数据包的数量，**当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1**。
慢启动算法的变化过程如下图：
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/tcp_congestion_control.jpg)

慢启动门限 ``ssthresh`` （slow start threshold）状态变量控制慢启动是否结束。
- 当 ``cwnd < ssthresh`` 时，使用慢启动算法。
- 当 ``cwnd >= ssthresh`` 时，就会使用「拥塞避免算法」。


#### 拥塞避免
拥塞避免算法后，它的规则是：**每当收到一个 ACK 时，cwnd 增加 1/cwnd**。
拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/tcp_congestion_avoidance.jpg)

---
当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：超时重传，快速重传。当发生了「超时重传」，则就会使用**拥塞发生算法**。当发生了「快速重传」，则就会使用**快速恢复算法**。

#### 拥塞发生
ssthresh 和 cwnd 的值会发生变化：
- ``ssthresh`` 设为 ``cwnd/2``，
- ``cwnd`` 重置为 1 （是恢复为 cwnd 初始化值，我这里假定 cwnd 初始化值 1）
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/tcp_congestion_occurrence.jpg)
这种方式太激进了，反应也很强烈，会造成网络卡顿。


#### 快速恢复
进入快速恢复之前，cwnd 和 ssthresh 已被更新了：
- ``cwnd = cwnd/2``，也就是设置为原来的一半;
- ``ssthresh = cwnd``;
  
然后，进入快速恢复算法如下：
- 拥塞窗口 ``cwnd = ssthresh + 3`` （ 3 的意思是确认有 3 个数据包被收到了）；
- 重传丢失的数据包；
- 如果再收到重复的 ACK，那么 cwnd 增加 1；
- 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；

快速恢复算法的变化过程如下图：
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/tcp_quick_recovery.jpg)


## 网络层
网络层提供发送主机和接受主机对之间传送**IP数据报**。网络层功能主要包括**数据转发** 和 **路由选择**
- 数据转发：将分组从路由器的输入接口转发到合适的输出接口
- 路由选择：使用路由算法来决定分组从发送主机到目标接收主机的路径

网络层设备主要是**路由器，具备IP地址和MAC地址**

1. **数据转发**
   - **基于目标的转发**：依赖于路由器内部的转发表和IP数据报的目标IP地址(传统方式)
   - **通用转发**：基于多个字段+流表(SDN方式)
2. **路由选择**
   - 路由选择算法：
     - link state
     - distance vector
   - 因特网中自治系统内部的路由选择算法
     - RIP
     - OSPF    
   - ISP之间的路由选择算法
     - BGP

### IP网络协议
IPv4数据报格式如下：
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/ip_protocol.png)

- 版本（Version）：版本字段占4bit，通信双方使用的版本必须一致。对于IPv4，字段的值是4。
- 首部长度 (Internet Header Length， IHL)：占4bit，首部长度说明首部有多少32位字（4字节）。这个字段的最小值是5，相当于5*4=20字节。
- 全长（Total Length）：这个16位字段定义了报文总长，包含首部和数据，单位为字节。这个字段的最小值是20（20字节首部+0字节数据），最大值是216-1=65,535
- 标识符（Identification）：占16位，这个字段主要被用来唯一地标识一个报文的所有分片，因为分片不一定按序到达，所以在重组时需要知道分片所属的报文。
- 分片偏移 （Fragment Offset）：这个13位字段指明了每个分片相对于原始报文开头的偏移量，以8字节作单位。
- 协议 （Protocol）：占8bit，这个字段定义了该报文数据区使用的协议。取值见部分IP协议号列表

部分IP协议号列表。
|协议字段值 | 协议名            | 缩写   | 
|:----:    | :---              |:----: |  
|1         | 互联网控制消息协议 | ICMP   | 
|2         | 互联网组管理协议   | IGMP   |
|6         | 传输控制协议       | TCP    | 
|17        | 用户数据报协议     | UDP    | 
|41        | IPv6封装          | ENCAP  | 
|89        | 开放式最短路径优先 | OSPF   | 
|132       | 流控制传输协议     | SCTP  | 


#### IP地址
IPv4使用32位（4字节）地址，因此地址空间中只有4,294,967,296（232）个地址。不过，一些地址是为特殊用途所保留的，如专用网络（约1800万个地址）和多播地址（约2.7亿个地址），这减少了可在互联网上路由的地址数量。随着地址不断被分配给最终用户，IPv4地址枯竭问题也在随之产生。基于分类网络、无类别域间路由和网络地址转换的地址结构重构显著地减少了地址枯竭的速度。IPv4地址通常被写作**点分十进制**的形式，即四个字节被分开用十进制写出，中间用点分隔。
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/ip_ipv4_address.jpg)

**IP 地址的分类**
IP 地址分类成了 5 种类型，分别是 A 类、B 类、C 类、D 类、E 类。
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/ip_addr_class2.jpg)

| 描述 | **A类IPv4地址** | **B类IPv4地址** | **C类IPv4地址** | **D类IPv4地址** | **E类IPv4地址** |
| --- | --- | --- | --- | --- | --- |
| **网络标志位** | 0 | 10 | 110 | 1110 | 1111 |
| **IP地址范围** | 0.0.0.0~127.255.255.255 | 128.0.0.0~191.255.255.255 | 192.0.0.0~223.255.255.255 | 224.0.0.0~239.255.255.255 | 240.0.0.0~255.255.255.255 |
| **可用IP地址范围** | 1.0.0.1~127.255.255.254 | 128.0.0.1~191.255.255.254 | 192.0.0.1~223.255.255.254 |  |  |
| **是否可以分配给主机使用** | 是 | 是 | 是 | 否 | 否 |
| **网络数量（个）** | 126 (2<sup>7</sup>\-2) | 16384 (2<sup>14</sup>) | 2097152 (2<sup>21</sup>) | \--- | \--- |
| **每个网络中可容纳主机数（个）** | 16777214 (2<sup>24</sup>\-2) | 65534 (2<sup>16</sup>\-2) | 254 (2<sup>8</sup>\-2) | \--- | \--- |
| **适用范围** | 大量主机的大型网络 | 中等规模主机数的网络 | 小型局域网 | 留给Internet体系结构委员会(IAB)使用[多播](https://zh.wikipedia.org/wiki/%E5%A4%9A%E6%92%AD "多播")地址| 保留，仅作为搜索、Internet的实验和开发用 |
| 备注 | 0.0.0.0为特殊地址，表示本网主机 |  |  |  | 255.255.255.255为特殊地址，用于定向广播 |

**A 类、 B 类、C类地址**有主机号，被用于**单播**，最大主机个数要减 2。为什么减2？ 
因为在 IP 地址中，有两个 IP 是特殊的，分别是主机号全为 1 和 全为 0 地址。
- 如果主机号全0，IP地址代表仅网络号指向的那个网段，该IP代表**一个网段**
- 如果主机号全1，IP地址代表网络号指向的全部主机，IP地址代表**广播地址**

**D 类和 E 类地址**是没有主机号的，所以不可用于主机 IP，D 类常被用于**多播(组播)**，E 类是预留的分类，暂时未使用。

IPv4地址空间分类如下：
| 前8位地址范围 | 类 | 路由形式 | 占地址总空间的比例 |
| --- | --- | --- | --- |
| 0-127 | A | [单播](https://zh.wikipedia.org/wiki/%E5%96%AE%E6%92%AD "单播") | 1/2 |
| 128-191 | B | [单播](https://zh.wikipedia.org/wiki/%E5%96%AE%E6%92%AD "单播") | 1/4 |
| 192-223 | C | [单播](https://zh.wikipedia.org/wiki/%E5%96%AE%E6%92%AD "单播") | 1/8 |
| 224-239 | D | [多播](https://zh.wikipedia.org/wiki/%E5%A4%9A%E6%92%AD "多播") | 1/16 |
| 240-255 | E | \- | 1/16 |


**单播、多播、广播**
- **单播**是指数据包在计算机网络的传输中，目的地址为单一目标的一种传输方式。通常所使用的网络协议大多采用单播传输，例如TCP和UDP。
- **广播**（英语：broadcast）是指将信息数据包发往指定网络范围内的所有设备，一对多。通常来说，**广播都是限制在局域网范围内**，比如以太网或令牌环网络。**ARP和DHCP使用广播协议**
- **多播**把信息同时传递给一组目的计算机，多播可以是一对多或多对多布置。**多播**可以不受局域网限制。多播通常应用于IP网络上的流媒体传输，如IPTV、多点视频会议（Multipoint videoconferencing） 等。


**子网**
C 类地址中最后 8 位是主机号，根据子网掩码可知从 8 位主机号中借用 2 位作为子网号。子网可以表示为 ``192.168.1.0/xx``
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/ip_subnet.jpg)


#### IP地址获取与DHCP协议
公网IP需要ISP统一管理，局域网IP需要组织内部人员管理。在局域网内部可以手动设置ip地址，也可以通过DHCP协议动态获取ip地址。

DHCP，动态主机配置协议，前身是BOOTP协议，是一个局域网的网络协议，使用UDP协议工作，常用的2个端口：67(DHCP server),68(DHCP client)。DHCP通常被用于局域网环境，主要作用是集中的管理、分配IP地址，使client动态的获得IP地址、Gateway地址、DNS服务器地址等信息，并能够提升地址的使用率。简单来说，DHCP就是一个不需要账号密码登录的、自动给内网机器分配IP地址等信息的协议。

DHCP 客户端进程监听的是 68 端口号，DHCP 服务端进程监听的是 67 端口号。 4 个步骤：
1. 客户端首先发起 **DHCP 发现报文**（DHCP DISCOVER） 的 IP 数据报，由于客户端没有 IP 地址，也不知道 DHCP 服务器的地址，所以使用的是 **UDP 广播**通信，其使用的广播目的地址是 255.255.255.255（端口 67） 并且使用 0.0.0.0（端口 68） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备。
2. DHCP 服务器收到 DHCP 发现报文时，用 **DHCP 提供报文**（DHCP OFFER） 向客户端做出响应。该报文仍然使用 IP 广播地址 255.255.255.255，该报文信息携带服务器提供可租约的 IP 地址、子网掩码、默认网关、DNS 服务器以及 IP 地址租用期。
3. 客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 **DHCP 请求报文**（DHCP REQUEST进行响应，回显配置的参数。
4. 最后，服务端用 **DHCP ACK** 报文对 DHCP 请求报文进行响应，应答所要求的参数。

为了解决 DHCP 服务器和客户端不是在同一个局域网内这一问题，就出现了 **DHCP 中继代理**。有了 DHCP 中继代理以后，**对不同网段的 IP 地址分配也可以由一个 DHCP 服务器统一进行管理**。
1. DHCP 客户端会向 DHCP 中继代理发送 DHCP 请求包，而 DHCP 中继代理在收到这个广播包以后，再以单播的形式发给 DHCP 服务器。
2. 服务器端收到该包以后再向 DHCP 中继代理返回应答，并由 DHCP 中继代理将此包广播给 DHCP 客户端 。

**参考：**
- [DHCP 详解](https://www.cnblogs.com/happygirl-zjj/p/5976526.html)
- [什么是DHCP？](https://info.support.huawei.com/info-finder/encyclopedia/zh/DHCP.html)
- [IPv4](https://zh.wikipedia.org/wiki/IPv4)


#### 网络地址转换(NAT)
NAT(Network Address Translation)是作为一种解决IPv4地址短缺以避免保留IP地址困难的方案而流行起来的。本地网络只有一个有效IP地址:
- 不需要从ISP分配一块地址，可用一个IP地址用于所有的（局域网）设备--省钱
- 可以在局域网改变设备的地址情况下而无须通知外界
- 可以改变ISP（地址变化）而不需要改变内部的设备地址
- 局域网内部的设备没有明确的地址，对外是不可见的--安全



**RFC1918规定了三块专有的地址，作为私有的内部组网使用：**

- A类：10.0.0.0—10.255.255.255      10.0.0.0/8
- B类：172.16.0.0—172.31.255.255   172.16.0.0/12
- C类：192.168.0.0—192.168.255.255 192.168.0.0/16

**三种NAT技术**
假设一种场景，公司对外的有两个公网IP地址是 191.4.4.1/191.4.4.2，有两台主机A和B，局域网地址分别是192.168.1.2和192.168.1.3
1. 静态NAT：静态NAT就是一对一映射，内部有多少私有地址需要和外部通信，就要配置多少外网IP地址与其对应，并不节省外网IP，所以一般不用
2. 动态NAT：动态NAT是在路由器上配置一个外网IP地址池，当内部有计算机需要和外部通信时，就从地址池里动态的取出一个外网IP，并将他们的对应关系绑定到NAT表中，通信结束后，这个外网IP才被释放，可供其他内部IP地址转换使用，这个DHCP租约IP有相似之处。
3. PAT(port address Translation，端口地址转换，也叫端口地址复用)：这是**最常用的NAT技术**，也是IPv4能够维持到今天的最重要的原因之一，它提供了一种多对一的方式，对多个内网IP地址，边界路由可以给他们分配一个外网IP，利用这个外网IP的不同端口和外部进行通信。后面详细介绍。

NAT 路由器包含**NAT转换表**。NAT是将私有IP地址通过边界路由转换成外网IP地址，在边界路由的NAT地址转换表记录下这个转换映射记录，当外部数据返回时，路由使用NAT技术查询NAT转换表，再将目标地址替换成内网用户IP地址。
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/ip_nat_trans.jpg)

由于 NAT/NAPT 都依赖于自己的转换表，因此会有以下的问题：
- 外部无法主动与 NAT 内部服务器建立连接，因为 NAPT 转换表没有转换记录。
- 转换表的生成与转换操作都会产生性能开销。
- 通信过程中，如果 NAT 路由器重启了，所有的 TCP 连接都将被重置。

解决方法：
- 改用 IPv6
- NAT 穿透技术


**参考：**
- [NAT 详解](https://www.cnblogs.com/beginmind/p/6380489.html)
- [网络地址转换](https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2#%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E7%AB%AF%E5%8F%A3%E8%BD%AC%E6%8D%A2%EF%BC%88NAPT%EF%BC%89)



#### IPv4 数据报分片与重组

网络链路有MTU (最大传输单元)–链路层帧所携带的最大数据长度(默认MTU = 1500 bytes)，不同的链路类型，不同的MTU。

大的IP数据报在网络上被分片(“fragmented”)
- 一个数据报被分割成若干个小的数据报
  - 相同的ID
  - 不同的偏移量
  - 最后一个分片标记为0
- “重组”只在最终的目标主机进行
- IP头部的信息被用于标识，排序相关分片

如果ip包超过 1500 字节，需要 ip 包分片才能完成发送。
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/link_fragmented.png)

**参考：**
- [什么是MTU（Maximum Transmission Unit）？](https://info.support.huawei.com/info-finder/encyclopedia/zh/MTU.html)


### ICMP协议
ICMP 全称是 Internet Control Message Protocol，也就是互联网控制报文协议。ICMP 主要的功能包括：**确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等**。

在 IP 通信中如果某个 IP 包因为某种原因未能达到目标地址，那么这个具体的原因将由 **ICMP 负责通知**。

<div align=center>
   <img src="https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/ip_icmp.webp" width = "80%" height = "80%">
</div>

> ICMP 的这种通知消息会使用 IP数据报进行发送 。

ICMP 大致可以分为两大类：
- 一类是用于诊断的查询消息，也就是「**查询报文类型**」
- 另一类是通知出错原因的错误消息，也就是「**差错报文类型**」

| 类型  | 查询 | 差错 |
| --- |  --- | --- |
| 0 - [响应回显](https://zh.wikipedia.org/wiki/Ping "Ping")  | ● |  |
| 1 and 2 |  | ● |
| 3 - 目的不可达  |  | ● |
| 4 - 源端关闭  |  | ● |
| 5 - 重定向  |  | ● |
| 8 - [请求回显](https://zh.wikipedia.org/wiki/Ping "Ping")  | ● |  |
| 9 - 路由器通告  | ● |  |
| 10 - 路由器请求  | ● |  |
| 11 - ICMP 超时  |  | ● |




### Ping 的工作原理

**ping命令的底层，用的是网络层的ICMP协议**。

- `127.0.0.1` 是**回环地址**。`localhost`是**域名**，但默认等于 `127.0.0.1`。
- **`ping` 回环地址和 `ping` 本机地址，是一样的**，走的是**lo0 "假网卡"**，都会经过网络层和数据链路层等逻辑，最后在快要出网卡前**狠狠拐了个弯**， 将数据插入到一个**链表**后就**软中断**通知 **ksoftirqd** 来进行**收数据**的逻辑，**压根就不出网络**。所以断网了也能 `ping` 通回环地址。
- 如果服务器 `listen` 的是 `0.0.0.0`，那么它表示本机上的所有IPV4地址。此时用`127.0.0.1`和本机地址**都可以**访问到服务。

## 链路层
交换机是链路层设备，交换机的MAC地址用不到

一些术语
- 主机和路由器是节点（网桥和交换机也是）：nodes
- 沿着通信路径,连接个相邻节点通信信道的是链路：links
   - 有线链路 
   - 无线链路
   - 局域网，共享性链路
- 第二层协议数据单元帧frame，封装数据报

**数据链路层**负责从一个节点通过链路将（帧中的）数据报发送到**相邻的物理节点**（一个子网内部的2节点）

链路层提供的服务：
- 成帧，链路接入
- 在相邻节点间（一个子网内）进行可靠的转发
- 差错检测和纠正

链路层功能在“**适配器**”上实现 (aka networkinterface card NIC) 或者在一个芯片组上
- 以太网卡，802.11 网卡; 以太网芯片组
- 实现链路层和相应的物理层功能
![](https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/link_adapter.jpg)


### 差错检测和纠正

### 多路访问链路和协议

- 信道划分
   - 把信道划分成小片（时间、频率、编码）
   - 分配片给每个节点专用
- 随机访问
   - 信道不划分，允许冲突
   - 冲突后恢复
- 依次轮流
  - 节点依次轮流
  - 但是有很多数据传输的节点可以获得较长的信道使用权

### 交换局域网(LANs)
#### ARP协议
地址解析协议（英语：Address Resolution Protocol，缩写：ARP）是一个**通过解析网络层地址(IP地址)来找寻数据链路层地址(MAC地址)的网络传输协议**，它在IPv4中极其重要。ARP也可能指是在多数操作系统中管理其相关地址的一个进程。ARP**在局域网内广播**，由下一跳的IP地址确定吓一跳的MAC地址。

ARP 借助 **ARP 请求与 ARP 响应**两种类型的包确定 MAC 地址。

<div align=center>
   <img src="https://images--hosting.oss-cn-chengdu.aliyuncs.com/cn/arp.webp" width = "60%" height = "60%">
</div>

- 主机会通过**广播发送 ARP 请求**，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。
- 当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包里的内容，如果 ARP 请求包中的目标 IP 地址与自己的 IP 地址一致，那么这个设备就将自己的 MAC 地址塞入 **ARP 响应包**返回给主机(单播回应)。

> 操作系统通常会把第一次通过 ARP 获取的 MAC 地址缓存起来，以便下次直接从缓存中找到对应 IP 地址的 MAC 地址。不过，MAC 地址的缓存是有一定期限的，超过这个期限，缓存的内容将被清除。

#### Ethernet

#### 802.11WLAN

#### VLANS

### 链路虚拟化：MPLS


